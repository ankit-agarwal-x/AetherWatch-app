{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fAxlrEewYxh",
        "outputId": "8a73b2c2-75f5-4403-c705-672ba1d58d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      kepid kepoi_name   kepler_name         ra  ra_err        ra_str  \\\n",
            "0  10797460  K00752.01  Kepler-227 b  291.93423     0.0  19h27m44.22s   \n",
            "1  10797460  K00752.02  Kepler-227 c  291.93423     0.0  19h27m44.22s   \n",
            "2  10811496  K00753.01           NaN  297.00482     0.0  19h48m01.16s   \n",
            "3  10848459  K00754.01           NaN  285.53461     0.0  19h02m08.31s   \n",
            "4  10854555  K00755.01  Kepler-664 b  288.75488     0.0  19h15m01.17s   \n",
            "\n",
            "         dec  dec_err       dec_str  koi_gmag  ...  koi_fpflag_co  \\\n",
            "0  48.141651      0.0  +48d08m29.9s    15.890  ...              0   \n",
            "1  48.141651      0.0  +48d08m29.9s    15.890  ...              0   \n",
            "2  48.134129      0.0  +48d08m02.9s    15.943  ...              0   \n",
            "3  48.285210      0.0  +48d17m06.8s    16.100  ...              0   \n",
            "4  48.226200      0.0  +48d13m34.3s    16.015  ...              0   \n",
            "\n",
            "   koi_fpflag_ec  koi_insol  koi_insol_err1  koi_insol_err2  koi_srho  \\\n",
            "0              0      93.59           29.45          -16.65   3.20796   \n",
            "1              0       9.11            2.87           -1.62   3.02368   \n",
            "2              0      39.30           31.04          -10.49   7.29555   \n",
            "3              0     891.96          668.95         -230.35   0.22080   \n",
            "4              0     926.16          874.33         -314.24   1.98635   \n",
            "\n",
            "   koi_srho_err1  koi_srho_err2  koi_fittype  koi_score  \n",
            "0        0.33173       -1.09986      LS+MCMC      1.000  \n",
            "1        2.20489       -2.49638      LS+MCMC      0.969  \n",
            "2       35.03293       -2.75453      LS+MCMC      0.000  \n",
            "3        0.00917       -0.01837      LS+MCMC      0.000  \n",
            "4        2.71141       -1.74541      LS+MCMC      1.000  \n",
            "\n",
            "[5 rows x 153 columns]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "# Correct table name for cumulative exoplanet data\n",
        "url = \"https://exoplanetarchive.ipac.caltech.edu/cgi-bin/nstedAPI/nph-nstedAPI\"\n",
        "params = {\n",
        "    \"table\": \"cumulative\",  # Use the correct table name\n",
        "    \"select\": \"*\",          # Select all columns\n",
        "    \"format\": \"csv\"         # Retrieve the data in CSV format\n",
        "}\n",
        "# Request the data\n",
        "response = requests.get(url, params=params)\n",
        "# Save the data to a file or load it into a DataFrame\n",
        "with open(\"exoplanets_cumulative.csv\", \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "# Load the CSV data into a DataFrame for further processing\n",
        "df = pd.read_csv(\"exoplanets_cumulative.csv\")\n",
        "# Display the first few rows of the data\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elqk8vBdwffM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835e7f72-8a7a-4533-b6ec-8a11253617cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Exoplanet Kepler-227 b (KOI: K00752.01) is loc...\n",
            "1    Exoplanet Kepler-227 c (KOI: K00752.02) is loc...\n",
            "2    Exoplanet nan (KOI: K00753.01) is located at R...\n",
            "3    Exoplanet nan (KOI: K00754.01) is located at R...\n",
            "4    Exoplanet Kepler-664 b (KOI: K00755.01) is loc...\n",
            "Name: text_description, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Define a function to convert each row into a textual description\n",
        "def row_to_text(row):\n",
        "    return f\"Exoplanet {row['kepler_name']} (KOI: {row['kepoi_name']}) is located at RA: {row['ra_str']} and Dec: {row['dec_str']}. \" \\\n",
        "           f\"It has a gmag of {row['koi_gmag']}, an insolation flux of {row['koi_insol']} (error: +{row['koi_insol_err1']}, -{row['koi_insol_err2']}), \" \\\n",
        "           f\"and a stellar density of {row['koi_srho']} (error: +{row['koi_srho_err1']}, -{row['koi_srho_err2']}).\"\n",
        "# Apply the function to create text descriptions for each row in the DataFrame\n",
        "df['text_description'] = df.apply(row_to_text, axis=1)\n",
        "# Preview the first few text descriptions\n",
        "print(df['text_description'].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "# Create a Hugging Face dataset from the text descriptions\n",
        "train_data = {\"text\": df['text_description'].tolist()}\n",
        "train_dataset = Dataset.from_dict(train_data)\n",
        "# Preview the dataset\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ajd6_Lc6zum",
        "outputId": "c07c4d5d-162d-4d89-f592-be39c8b5a6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 9564\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. First, let's create a function to format our prompts more effectively\n",
        "def format_prompt(question):\n",
        "    return f\"Question: {question}\\nAnswer:\"\n",
        "\n",
        "# 2. Improved generation function with adjusted parameters\n",
        "def generate_exoplanet_text(prompt, model, tokenizer, max_length=200):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    formatted_prompt = format_prompt(prompt)\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.9,        # Slightly increased for more variety\n",
        "        top_p=0.95,            # Slightly increased\n",
        "        top_k=50,              # Added top_k parameter\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        no_repeat_ngram_size=2,  # Prevent repetition of 2-grams\n",
        "        num_beams=5             # Use beam search\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Remove the prompt from the generated text\n",
        "    response = generated_text.replace(formatted_prompt, \"\").strip()\n",
        "    return response\n",
        "\n",
        "# 3. Test prompts\n",
        "test_prompts = [\n",
        "    \"Tell me about Kepler-22b\",\n",
        "    \"What are the characteristics of hot Jupiters?\",\n",
        "    \"Describe the most Earth-like exoplanet\",\n",
        "    \"List some interesting facts about exoplanets\",\n",
        "    \"What is the largest known exoplanet?\"\n",
        "]\n",
        "\n",
        "# 4. Test the model and print results\n",
        "print(\"Testing the model with various prompts:\\n\")\n",
        "for prompt in test_prompts:\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    try:\n",
        "        response = generate_exoplanet_text(prompt, model, tokenizer)\n",
        "        if response:\n",
        "            print(f\"Generated Response: {response}\\n\")\n",
        "        else:\n",
        "            print(\"No response generated.\\n\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {str(e)}\\n\")\n",
        "\n",
        "# 5. Optional: Test with a sample from our training data\n",
        "print(\"Testing with a sample from our training data:\")\n",
        "sample_data = train_dataset['text'][0]\n",
        "print(f\"Sample data: {sample_data[:100]}...\")  # Print first 100 characters\n",
        "sample_prompt = \"Describe this exoplanet:\"\n",
        "response = generate_exoplanet_text(sample_prompt, model, tokenizer)\n",
        "print(f\"Generated Response: {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7ElT-E8EdWh",
        "outputId": "3624f613-488e-49d0-b4b1-44e24069a527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model with various prompts:\n",
            "\n",
            "Prompt: Tell me about Kepler-22b\n",
            "Generated Response: It is located at RA: 19h21m54.07s and Dec: +38d36m59.0s. It has a gmag of 15.723, an insolation flux of 5.81 (error: -2.73, --1.66), and a stellar density of 0.96779 (0.08622, -0m11.83895).\n",
            "\n",
            "Prompt: What are the characteristics of hot Jupiters?\n",
            "Generated Response: 1.064 (error: +1.01, --0.42), --1 year.056\n",
            "\n",
            "Prompt: Describe the most Earth-like exoplanet\n",
            "Generated Response: 0.038 (error: +0.03, --1.01),\n",
            "0.03901, and\n",
            "\n",
            "Prompt: List some interesting facts about exoplanets\n",
            "Generated Response: 1.04 (error: +1.03, --0.45),\n",
            "\n",
            "Prompt: What is the largest known exoplanet?\n",
            "Generated Response: It is located at RA: 19h26m59.87s and Dec: +38d46m26.3s. It has a gmag of 15.821, an insolation flux of 0.73 (error: -0.45, --0%), and a stellar density of 1.96484 (0e-05, -1.09895).\n",
            "\n",
            "Testing with a sample from our training data:\n",
            "Sample data: Exoplanet Kepler-227 b (KOI: K00752.01) is located at RA: 19h27m44.22s and Dec: +48d08m29.9s. It has...\n",
            "Generated Response: It has a gmag of 14.903, an insolation flux of 0.65 (error: +0.44, --0), and a stellar density of 1.06577\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "\n",
        "# 1. Set up tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# 2. Modified tokenization function to include labels\n",
        "def tokenize_function(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        return_special_tokens_mask=True\n",
        "    )\n",
        "    tokenized_inputs[\"labels\"] = tokenized_inputs[\"input_ids\"].copy()\n",
        "    return tokenized_inputs\n",
        "\n",
        "# 3. Tokenize the dataset\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "\n",
        "# 4. Load the model\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# 5. Set up training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./exoplanet-gpt2-improved\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    fp16=True,\n",
        "    warmup_steps=500\n",
        ")\n",
        "\n",
        "# 6. Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model_path = \"./exoplanet-gpt2-final-improved\"\n",
        "model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "\n",
        "\n",
        "# 9. Function to generate text\n",
        "def generate_exoplanet_text(prompt, model, tokenizer, max_length=200):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479,
          "referenced_widgets": [
            "9ef60edcacc245a1a3873b17f70172bf",
            "4f587e5163dd45318e187d27cec03eac",
            "35d7177007e9437cb8752e4744b57d71",
            "8d75c1da23b44a50b7cfd1e0aec41d6d",
            "08152b2d90fb4a3182639d3d885d64bf",
            "657a0a3e007d442a84b80bb06f73bdc4",
            "31f6295dc5294bc7a72c6a29f63fffd4",
            "8fbc9b5762b34758b3db2d613fad97ff",
            "f770d892d5994603a7d28cb5f88b0b04",
            "bfdf2e25ffeb40ad87e733f0d31292cb",
            "bc7aebafebba4d50a92333b881691c8c"
          ]
        },
        "id": "CiveKC6L6356",
        "outputId": "7c4fa6dc-f1d2-4893-d528-d8b8ed1bdd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9564 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ef60edcacc245a1a3873b17f70172bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='954' max='5975' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 954/5975 08:39 < 45:42, 1.83 it/s, Epoch 0.80/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.825500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.388700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.251600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.242400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.241000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.235200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.234200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.233700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.231500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, tokenizer):\n",
        "    test_questions = [\n",
        "        \"Tell me about Kepler-22b\",\n",
        "        \"What are the characteristics of hot Jupiters?\",\n",
        "        \"Describe the most Earth-like exoplanet\",\n",
        "        \"How are exoplanets discovered?\",\n",
        "        \"What makes an exoplanet habitable?\"\n",
        "    ]\n",
        "\n",
        "    print(\"Testing the improved model:\\n\")\n",
        "    for question in test_questions:\n",
        "        print(f\"Question: {question}\")\n",
        "\n",
        "        inputs = tokenizer(f\"Question: {question}\\nAnswer:\", return_tensors=\"pt\")\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=200,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            top_k=50,\n",
        "            no_repeat_ngram_size=2,\n",
        "            num_beams=5\n",
        "        )\n",
        "\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        response = response.split(\"Answer:\")[-1].strip()\n",
        "        print(f\"Answer: {response}\\n\")\n",
        "\n",
        "# Test the model\n",
        "test_model(model, tokenizer)"
      ],
      "metadata": {
        "id": "Q9skxPT-GdCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "def load_model_and_tokenizer(model_path):\n",
        "    \"\"\"Load the fine-tuned model and tokenizer\"\"\"\n",
        "    try:\n",
        "        model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "        tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        return model, tokenizer\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def generate_response(prompt, model, tokenizer, max_length=200):\n",
        "    \"\"\"Generate a response from the model\"\"\"\n",
        "    try:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        formatted_prompt = f\"Question: {prompt}\\nAnswer:\"\n",
        "        inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            temperature=0.7,\n",
        "            top_p=0.95,\n",
        "            top_k=50,\n",
        "            no_repeat_ngram_size=2,\n",
        "            num_beams=5,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        # Extract just the answer part\n",
        "        answer = full_response.split(\"Answer:\")[-1].strip()\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {str(e)}\"\n",
        "\n",
        "def test_specific_examples(model, tokenizer, df):\n",
        "    \"\"\"Test the model with specific examples from the dataset\"\"\"\n",
        "    print(\"\\n=== Testing Specific Examples ===\")\n",
        "\n",
        "    # Test with 3 random specific exoplanets from the dataset\n",
        "    for _ in range(3):\n",
        "        row = df.iloc[random.randint(0, len(df)-1)]\n",
        "        name = row['kepler_name'] if pd.notna(row['kepler_name']) else row['kepoi_name']\n",
        "        prompt = f\"Tell me about the exoplanet {name}\"\n",
        "\n",
        "        print(f\"\\nPrompt: {prompt}\")\n",
        "        response = generate_response(prompt, model, tokenizer)\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "def test_general_questions(model, tokenizer):\n",
        "    \"\"\"Test the model with general questions about exoplanets\"\"\"\n",
        "    print(\"\\n=== Testing General Questions ===\")\n",
        "\n",
        "    general_questions = [\n",
        "        \"What are hot Jupiters?\",\n",
        "        \"How are exoplanets discovered?\",\n",
        "        \"What makes an exoplanet potentially habitable?\",\n",
        "        \"What is the Kepler Space Telescope?\",\n",
        "        \"Why are exoplanets important to study?\"\n",
        "    ]\n",
        "\n",
        "    for question in general_questions:\n",
        "        print(f\"\\nPrompt: {question}\")\n",
        "        response = generate_response(question, model, tokenizer)\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "def test_complex_queries(model, tokenizer):\n",
        "    \"\"\"Test the model with more complex or comparative queries\"\"\"\n",
        "    print(\"\\n=== Testing Complex Queries ===\")\n",
        "\n",
        "    complex_questions = [\n",
        "        \"Compare Earth-like exoplanets to hot Jupiters\",\n",
        "        \"What are the challenges in detecting small rocky exoplanets?\",\n",
        "        \"How do scientists determine the composition of exoplanets?\",\n",
        "        \"What role does stellar type play in exoplanet detection?\",\n",
        "        \"Describe the different methods used to find exoplanets\"\n",
        "    ]\n",
        "\n",
        "    for question in complex_questions:\n",
        "        print(f\"\\nPrompt: {question}\")\n",
        "        response = generate_response(question, model, tokenizer)\n",
        "        print(f\"Response: {response}\")\n",
        "\n",
        "def main_test_suite():\n",
        "    \"\"\"Main function to run all tests\"\"\"\n",
        "    model_path = \"./exoplanet-gpt2-final\"  # Update this to your model path\n",
        "    model, tokenizer = load_model_and_tokenizer(model_path)\n",
        "\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"Failed to load model or tokenizer. Exiting.\")\n",
        "        return\n",
        "\n",
        "    print(\"=== Starting Comprehensive Test Suite ===\")\n",
        "\n",
        "    # Test specific examples from the dataset\n",
        "    test_specific_examples(model, tokenizer, df)\n",
        "\n",
        "    # Test general questions\n",
        "    test_general_questions(model, tokenizer)\n",
        "\n",
        "    # Test complex queries\n",
        "    test_complex_queries(model, tokenizer)\n",
        "\n",
        "# Run the test suite\n",
        "if __name__ == \"__main__\":\n",
        "    main_test_suite()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "f82451e315004c6c85376c482b2b3c05",
            "aa57efad7fd64d4dbff2099e1b13be77",
            "a56dce0ab5294474ba3eb25304b22236",
            "97d178175f0645b0af131f0b91c9a7f2",
            "3d650b51cf144431ad7bdb4c78c7c4ef",
            "6286cbc6c03943b193135aa8f0350541",
            "285f9e1166ae4701b47d4e7674f6d2f8",
            "14fc7414acba446b9a93883fb87a4ad8",
            "444029f9fb8a4b8bb77792ad2d33ebb4",
            "e817a3190caf4a39b838f641f783e63a",
            "ea8293735f294d80bac4212be1ce545c"
          ]
        },
        "id": "pQjPgvWuE71M",
        "outputId": "11c8c831-4dbe-4e39-d3ab-7fb4420ebc7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/9567 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f82451e315004c6c85376c482b2b3c05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample training examples:\n",
            "\n",
            "Example 1:\n",
            "Question: What is Kepler-227 b?\n",
            "Answer: Kepler-227 b is an exoplanet discovered by the Kepler space telescope. It is located at coordinates RA 19h27m44.22s and Dec +48d08m29.9s in the sky. This exoplanet likely has a hot, with an insolation flux of 93.59 relative to Earth. The star it orbits has a density 3.21 times that of the Sun.\n",
            "\n",
            "Example 2:\n",
            "Question: What is Kepler-227 c?\n",
            "Answer: Kepler-227 c is an exoplanet discovered by the Kepler space telescope. It is located at coordinates RA 19h27m44.22s and Dec +48d08m29.9s in the sky. This exoplanet likely has a moderate temperature, with an insolation flux of 9.11 relative to Earth. The star it orbits has a density 3.02 times that of the Sun.\n",
            "\n",
            "Example 3:\n",
            "Question: What are some interesting exoplanets?\n",
            "Answer: K00753.01 is an exoplanet discovered by the Kepler space telescope. It is located at coordinates RA 19h48m01.16s and Dec +48d08m02.9s in the sky. This exoplanet likely has a hot, with an insolation flux of 39.30 relative to Earth. The star it orbits has a density 7.30 times that of the Sun.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LnEregpmFwec"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ef60edcacc245a1a3873b17f70172bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f587e5163dd45318e187d27cec03eac",
              "IPY_MODEL_35d7177007e9437cb8752e4744b57d71",
              "IPY_MODEL_8d75c1da23b44a50b7cfd1e0aec41d6d"
            ],
            "layout": "IPY_MODEL_08152b2d90fb4a3182639d3d885d64bf"
          }
        },
        "4f587e5163dd45318e187d27cec03eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_657a0a3e007d442a84b80bb06f73bdc4",
            "placeholder": "​",
            "style": "IPY_MODEL_31f6295dc5294bc7a72c6a29f63fffd4",
            "value": "Map: 100%"
          }
        },
        "35d7177007e9437cb8752e4744b57d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fbc9b5762b34758b3db2d613fad97ff",
            "max": 9564,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f770d892d5994603a7d28cb5f88b0b04",
            "value": 9564
          }
        },
        "8d75c1da23b44a50b7cfd1e0aec41d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfdf2e25ffeb40ad87e733f0d31292cb",
            "placeholder": "​",
            "style": "IPY_MODEL_bc7aebafebba4d50a92333b881691c8c",
            "value": " 9564/9564 [00:06&lt;00:00, 1273.53 examples/s]"
          }
        },
        "08152b2d90fb4a3182639d3d885d64bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "657a0a3e007d442a84b80bb06f73bdc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f6295dc5294bc7a72c6a29f63fffd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbc9b5762b34758b3db2d613fad97ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f770d892d5994603a7d28cb5f88b0b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfdf2e25ffeb40ad87e733f0d31292cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7aebafebba4d50a92333b881691c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f82451e315004c6c85376c482b2b3c05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa57efad7fd64d4dbff2099e1b13be77",
              "IPY_MODEL_a56dce0ab5294474ba3eb25304b22236",
              "IPY_MODEL_97d178175f0645b0af131f0b91c9a7f2"
            ],
            "layout": "IPY_MODEL_3d650b51cf144431ad7bdb4c78c7c4ef"
          }
        },
        "aa57efad7fd64d4dbff2099e1b13be77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6286cbc6c03943b193135aa8f0350541",
            "placeholder": "​",
            "style": "IPY_MODEL_285f9e1166ae4701b47d4e7674f6d2f8",
            "value": "Map: 100%"
          }
        },
        "a56dce0ab5294474ba3eb25304b22236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14fc7414acba446b9a93883fb87a4ad8",
            "max": 9567,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_444029f9fb8a4b8bb77792ad2d33ebb4",
            "value": 9567
          }
        },
        "97d178175f0645b0af131f0b91c9a7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e817a3190caf4a39b838f641f783e63a",
            "placeholder": "​",
            "style": "IPY_MODEL_ea8293735f294d80bac4212be1ce545c",
            "value": " 9567/9567 [00:08&lt;00:00, 1037.65 examples/s]"
          }
        },
        "3d650b51cf144431ad7bdb4c78c7c4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6286cbc6c03943b193135aa8f0350541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "285f9e1166ae4701b47d4e7674f6d2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14fc7414acba446b9a93883fb87a4ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444029f9fb8a4b8bb77792ad2d33ebb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e817a3190caf4a39b838f641f783e63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8293735f294d80bac4212be1ce545c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}